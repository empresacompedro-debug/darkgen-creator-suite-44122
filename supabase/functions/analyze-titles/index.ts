import { serve } from "https://deno.land/std@0.168.0/http/server.ts";
import { createClient } from "https://esm.sh/@supabase/supabase-js@2";

const corsHeaders = {
  'Access-Control-Allow-Origin': '*',
  'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',
};

interface AnalysisResult {
  markdownReport: string;
}

serve(async (req) => {
  if (req.method === 'OPTIONS') {
    return new Response(null, { headers: corsHeaders });
  }

  try {
    const { rawData, aiModel = 'claude-sonnet-4-5' } = await req.json();

    console.log('Received request with model:', aiModel);
    console.log('Raw data length:', rawData?.length);

    if (!rawData || rawData.trim().length === 0) {
      throw new Error('Dados vazios. Por favor, cole os dados do YouTube.');
    }

    // Get Supabase client
    const supabaseUrl = Deno.env.get('SUPABASE_URL')!;
    const supabaseKey = Deno.env.get('SUPABASE_SERVICE_ROLE_KEY')!;
    const supabase = createClient(supabaseUrl, supabaseKey);

    // Get user from auth header
    const authHeader = req.headers.get('Authorization');
    let userId: string | null = null;
    
    if (authHeader) {
      const token = authHeader.replace('Bearer ', '');
      const { data: { user }, error: authError } = await supabase.auth.getUser(token);
      if (!authError && user) {
        userId = user.id;
      }
    }

    console.log('User ID:', userId);

    // Get API key based on model
    let apiKey: string | undefined;
    let apiUrl: string;
    let requestBody: any;

    if (aiModel.includes('claude')) {
      apiKey = Deno.env.get('ANTHROPIC_API_KEY');
      apiUrl = 'https://api.anthropic.com/v1/messages';
      
      if (!apiKey) {
        throw new Error('ANTHROPIC_API_KEY n√£o configurada');
      }
    } else if (aiModel.includes('gemini')) {
      apiKey = Deno.env.get('GEMINI_API_KEY');
      apiUrl = `https://generativelanguage.googleapis.com/v1beta/models/${aiModel}:generateContent?key=${apiKey}`;
      
      if (!apiKey) {
        throw new Error('GEMINI_API_KEY n√£o configurada');
      }
    } else if (aiModel.includes('gpt')) {
      apiKey = Deno.env.get('OPENAI_API_KEY');
      apiUrl = 'https://api.openai.com/v1/chat/completions';
      
      if (!apiKey) {
        throw new Error('OPENAI_API_KEY n√£o configurada');
      }
    } else {
      throw new Error(`Modelo n√£o suportado: ${aiModel}`);
    }

    // Build comprehensive markdown prompt
    const prompt = `CONTEXTO:
Voc√™ √© um especialista em an√°lise de performance de conte√∫do no YouTube, especializado em identificar padr√µes virais em t√≠tulos de v√≠deos de qualquer nicho/subnicho e microsubnicho.

TAREFA:
Analise os t√≠tulos fornecidos e crie uma resposta seguindo RIGOROSAMENTE este modelo:

# üèÜ **TEMA CAMPE√ÉO ABSOLUTO**
[Identificar o tema principal de maior sucesso combinando 3 elementos: CONTEXTO + CONFLITO + RESULTADO]

## **üîë TOP 10 PALAVRAS-CHAVE MAIS REPETIDAS**
1. **"[Palavra/Frase]"** - [N¬∫ vezes]x (m√©dia [X]K views)
2. **"[Palavra/Frase]"** - [N¬∫ vezes]x (m√©dia [X]K views)
[Continue at√© 10...]

## **üìä 5 SUBNICHOS CAMPE√ïES**
1. **[Nome do Subnicho]** - M√©dia [X]K views
2. **[Nome do Subnicho]** - M√©dia [X]K views
[Continue at√© 5...]

## **üéØ 10 MICRONICHOS CAMPE√ïES**
1. **"[Descri√ß√£o Espec√≠fica do Micronicho]"** - [X]K m√©dia
2. **"[Descri√ß√£o Espec√≠fica do Micronicho]"** - [X]K m√©dia
[Continue at√© 10...]

## **‚ú® 50 NOVOS T√çTULOS BASEADOS NOS 5 CAMPE√ïES**

### **BASEADOS NO CAMPE√ÉO 1 ([X]K views):**
**"[T√≠tulo original completo]"**
1. [Nova varia√ß√£o mantendo estrutura mas mudando detalhes]
2. [Nova varia√ß√£o mantendo estrutura mas mudando detalhes]
[Continue at√© 10...]

### **BASEADOS NO CAMPE√ÉO 2 ([X]K views):**
**"[T√≠tulo original completo]"**
11. [Nova varia√ß√£o mantendo estrutura mas mudando detalhes]
12. [Nova varia√ß√£o mantendo estrutura mas mudando detalhes]
[Continue at√© 20...]

[Repetir para Campe√µes 3, 4 e 5 at√© completar 50 t√≠tulos]

## üí° **8 ELEMENTOS-CHAVE PARA REPLICAR**
1. **[Elemento]** (sempre incluir exemplo)
2. **[Elemento]** (sempre incluir exemplo)
[Continue at√© 8...]

## üöÄ **MICRONICHOS PARA REPLICAR**

### **PRIORIDADE 1 (FAZER IMEDIATAMENTE):**
- [Micronicho 1 com descri√ß√£o]
- [Micronicho 2 com descri√ß√£o]
- [Micronicho 3 com descri√ß√£o]

### **PRIORIDADE 2 (ALTA PERFORMANCE):**
- [Micronicho 4 com descri√ß√£o]
- [Micronicho 5 com descri√ß√£o]
- [Micronicho 6 com descri√ß√£o]

### **PRIORIDADE 3 (BOA PERFORMANCE):**
- [Micronicho 7 com descri√ß√£o]
- [Micronicho 8 com descri√ß√£o]
- [Micronicho 9 com descri√ß√£o]

## ‚≠ê **10 T√çTULOS FINAIS COM MAIOR POTENCIAL**

**1. MICRONICHO: [Nome do Micronicho] [Potencial: XXK+ views]**
\`\`\`
[T√≠tulo completo de 15-20 palavras seguindo a f√≥rmula identificada]
\`\`\`

**2. MICRONICHO: [Nome do Micronicho] [Potencial: XXK+ views]**
\`\`\`
[T√≠tulo completo de 15-20 palavras seguindo a f√≥rmula identificada]
\`\`\`

[Repetir para 10 t√≠tulos]

=== DADOS DE ENTRADA ===
${rawData}

IMPORTANTE: 
- N√ÉO adicione se√ß√µes extras
- N√ÉO mude a ordem das se√ß√µes
- MANTENHA exatamente a formata√ß√£o mostrada
- USE os mesmos emojis indicados
- SEMPRE baseie as varia√ß√µes nos 5 campe√µes identificados
- Retorne APENAS o markdown formatado, sem explica√ß√µes adicionais`;

    console.log('Sending request to AI model...');

    let analysis: AnalysisResult;

    // Make API request based on model
    if (aiModel.includes('claude')) {
      const response = await fetch(apiUrl, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'x-api-key': apiKey!,
          'anthropic-version': '2023-06-01',
        },
        body: JSON.stringify({
          model: aiModel,
          max_tokens: 8192,
          messages: [
            {
              role: 'user',
              content: prompt,
            },
          ],
        }),
      });

      if (!response.ok) {
        const errorText = await response.text();
        console.error('Claude API error:', errorText);
        throw new Error(`Claude API error: ${response.status} - ${errorText}`);
      }

      const data = await response.json();
      console.log('Claude response received');
      
      const markdownReport = data.content[0].text;
      analysis = { markdownReport };
      
    } else if (aiModel.includes('gemini')) {
      const response = await fetch(apiUrl, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          contents: [{
            parts: [{
              text: prompt,
            }],
          }],
          generationConfig: {
            temperature: 0.7,
            maxOutputTokens: 8192,
          },
        }),
      });

      if (!response.ok) {
        const errorText = await response.text();
        console.error('Gemini API error:', errorText);
        throw new Error(`Gemini API error: ${response.status} - ${errorText}`);
      }

      const data = await response.json();
      console.log('Gemini response received:', JSON.stringify(data, null, 2));
      
      if (!data.candidates || !data.candidates[0]) {
        console.error('Invalid Gemini response structure:', data);
        throw new Error('Invalid Gemini API response: missing candidates');
      }
      
      if (!data.candidates[0].content || !data.candidates[0].content.parts || !data.candidates[0].content.parts[0]) {
        console.error('Invalid Gemini content structure:', data.candidates[0]);
        throw new Error('Invalid Gemini API response: missing content parts');
      }
      
      const markdownReport = data.candidates[0].content.parts[0].text;
      analysis = { markdownReport };
      
    } else if (aiModel.includes('gpt')) {
      const response = await fetch(apiUrl, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${apiKey}`,
        },
        body: JSON.stringify({
          model: aiModel,
          messages: [
            {
              role: 'system',
              content: 'Voc√™ √© um especialista em an√°lise de dados do YouTube. Retorne apenas JSON v√°lido.',
            },
            {
              role: 'user',
              content: prompt,
            },
          ],
          temperature: 0.7,
          max_tokens: 8192,
        }),
      });

      if (!response.ok) {
        const errorText = await response.text();
        console.error('OpenAI API error:', errorText);
        throw new Error(`OpenAI API error: ${response.status} - ${errorText}`);
      }

      const data = await response.json();
      console.log('OpenAI response received');
      
      const markdownReport = data.choices[0].message.content;
      analysis = { markdownReport };
    } else {
      throw new Error('Modelo n√£o suportado');
    }

    console.log('Analysis parsed successfully');

    // Save to database if user is authenticated
    if (userId) {
      console.log('Saving analysis to database...');
      
      const { error: insertError } = await supabase
        .from('title_analyses')
        .insert({
          user_id: userId,
          raw_data: rawData,
          ai_model: aiModel,
          analysis_result: analysis,
        });

      if (insertError) {
        console.error('Error saving to database:', insertError);
        // Don't throw, just log - we still want to return the analysis
      } else {
        console.log('Analysis saved to database successfully');
      }
    }

    return new Response(
      JSON.stringify(analysis),
      {
        headers: { ...corsHeaders, 'Content-Type': 'application/json' },
      }
    );

  } catch (error) {
    console.error('Error in analyze-titles function:', error);
    
    const errorMessage = error instanceof Error ? error.message : 'Erro ao processar an√°lise';
    const errorDetails = error instanceof Error ? error.toString() : String(error);
    
    return new Response(
      JSON.stringify({
        error: errorMessage,
        details: errorDetails,
      }),
      {
        status: 500,
        headers: { ...corsHeaders, 'Content-Type': 'application/json' },
      }
    );
  }
});
